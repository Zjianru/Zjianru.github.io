---
layout:     post
title:      文章拿在手 Redis 面试不用愁（一）
subtitle:   Redis 数据持久化策略详解
date:       2019-04-19
author:     Alessio
header-img: img/PostBack_03.jpg
catalog: true
tags:
    - Redis
---
## 从持久化开始

我们在开发中不止一次地碰到过数据持久化这个名词，我们不厌其烦地再解释一遍
>
> 持久化，本质上来说，是一种将程序数据在持久状态和瞬时状态间转换的机制
>
持久化的应用场景有很多，在不同场景下其含义也不尽相同，在 Redis 里我们大可以把 持久化 看作是 数据从内存中转存到磁盘上的过程。

**持久化能够解决因为进程退出而造成的数据丢失（不一致）问题**

Redis 作为内存数据存储，对于数据持久化机制的实现也提供了两种不同的思路，即我们即将谈到的 `RDB` 和 `AOF`

## RDB

RDB 持久化机制，可以通过手动或自动触发

### 手动 RDB

手动触发 RDB 需要两个关键命令 `save` 和 `bgsave`。

#### `save` 命令

`save` 命令会立刻开始 RDB 过程，将内存中的数据转移到磁盘上，在这个过程中，RDB 操作会阻塞当前主进程——在这个时候，你的 Redis 就进入“假死” 状态了。

在这个过程中，主进程将不会对外服务，而且对于比较大的实例来说，这个过程耗费的时间略长，线上环境一般是不采用的。

在 RDB 操作结束后，主进程不再被阻塞，生成的 .rdb 数据文件会按照配置文件中的 `dir` 配置保存妥当，文件名则通过 `dbfilename` 配置来指定

#### `bgsave` 命令

`bgsave` 相对则会 “温柔些” 。在执行 `bgsave` 命令时，主进程会执行 fork 操作创建一个子进程，由这个进程来完成 RDB 操作。

在这个过程中，由于使用了子进程，所以不会阻塞主进程——你的 Redis 不会“假死”啦~

同样的，新生成的 `.rdb` 文件也会按照相应的配置完成 “安家落户”。

### 自动 RDB

自动 RDB 首先会**基于配置**来决定要不要执行自动配置 如下配置文件示例：

```bash
################################ SNAPSHOTTING  ################################
#
# Save the DB on disk:
#
#   save <seconds> <changes>
#
#   Will save the DB if both the given number of seconds and the given
#   number of write operations against the DB occurred.
#
#   In the example below the behaviour will be to save:
#   after 900 sec (15 min) if at least 1 key changed
#   after 300 sec (5 min) if at least 10 keys changed
#   after 60 sec if at least 10000 keys changed
#
#   Note: you can disable saving completely by commenting out all "save" lines.
#
#   It is also possible to remove all the previously configured save
#   points by adding a save directive with a single empty string argument
#   like in the following example:
#
#   save ""

save 900 1
save 300 10
save 60 10000
```
第二种情况，如果在主从复制的场景下，**新的从节点加入**，或者 **从节点执行全量复制操作**，主节点会自动执行 `bgsave` 生成 RDB 文件并分发给从节点

第三种情况，当执行 `debug reload` 命令，重新加载 Redis 时，也会触发 `save` 操作 

第四种情况，当我们使用 `redis-cli -p <port> shutdown` 命令来关闭 Redis 的时候，如果没有开启 AOF 持久化，那么也会默认执行 `bgsave` 操作

### 关于 RDB 文件

1. RDB 文件默认通过 `LZF 算法` 来完成压缩处理，方便网络传输或保存到磁盘上
2. 如果之前存在 RDB 文件， 新产生的 RDB 文件会**原子**地替换掉旧的 RDB 文件
3. 如果在 bgsave 命令仍在执行时重新发送 besave 命令，Redis 会直接返回该命令
4. 其实在 bgsave 的时候，也会在 fork 操作的时候阻塞主进程，但是其时间消耗几乎可忽略不计
5. 可使用 官方工具 `redis-check-dump` 来对 RDB 文件进行检测

## AOF
### AOF 介绍
AOF 是 Redis 提供的第二种持久化方案，与 RDB 有很大的不同。全称 ` append only file ` ，使用独立日志的方式记录每次的写命令。

上述的 RDB 持久化方案，除了笨重（RDB 文件是对当前数据的全量记录），在实时性方面也存在诸多问题——在生产环境中 RDB 文件是不能做到实时记录的，每次命令写入都要执行一次 `save` 或 `bgsave`，对IO资源也是一种极大程度的挥霍，我们需要一种更加轻量，更加节省开销的记录方式

由此，AOF 应运而生。

在 Redis 中 AOF 是默认 **不开启** 的，想过要开启 AOF 需要我们在配置文件中开启 `appendonly yes` 配置行来生效。

其 AOF 文件的命名，则通过 `appendfilename "appendonly.aof"` 配置行来指定。

其保存路径与RDB 相同 ，通过 `dir` 配置行来指定

### AOF 工作流程详解

AOF 的工作流程，分如下几个步骤:

1. 命令写入
2. 文件同步
3. 文件重写
4. 启动加载

在开启 AOF 之后，所有的写命令都会写入到 **AOF 缓冲区** 中

AOF 缓冲区会根据相应的策略配置，将缓冲区的内容向硬盘做同步

持续上述两个步骤，在 AOF 文件膨胀到一个 “不可容忍” 的大小之后，会触发 AOF 重写，将现有 AOF 文件进行压缩

当 Redsi 服务器重启时候，会根据 AOF 文件来完成数据恢复
#### 命令写入

AOF 采用文本追加的方式来完成命令写入，新的命令会追加在现有命令的尾部。

而且新的命令会首先存放在我们在上面提到的 AOF 缓冲区，之后才会根据 sync 策略调用 `fsync` / `fdatasync` 刷入硬盘设备。

这种处理方式在各大开源软件或操作系统中屡见不鲜，例如 Linux 内核中提供了页高速缓冲，java 中提供了StringBuffer 对象。这样的处理方式使得磁盘 IO 性能大大提高。

使用缓冲区也是基于 Redis 本身设计的考量——单线程的 Redis 如果每次对 AOF 文件的写入都要在第一时间刷入磁盘，将会极大程度地拖慢IO设备的吞吐能力。使用缓冲区设计，在性能和安全性上都做出了保证。

#### 文件同步

那么，AOF 缓冲区的内容是基于什么考量来完成刷入的呢？在配置文件中我们有如下的选择

```bash
appendfsync always
appendfsync everysec
appendfsync no
```
三种刷盘方式，实际上是三种处理策略
1. always

`always` 配置会在命令进入的第一时间完成刷盘，但是这样 AOF 缓冲区形同虚设，我们的操作仿佛回到了“刀耕火种”年代.

2. no 

`no` 不进行具体配置，由操作系统执行同步策略。操作系统同步周期不可控，同时也加大了每次同步的数据量，虽然性能会得到提升，但数据安全性却不能得到保障

3. everysec

`everysec` 每秒完成一次刷盘操作。这是我们在开发环境中常用的，兼顾安全和性能。也是 Redis 官方推荐的策略。从理论上说，使用 everysec 方案，即使发生宕机，我们最多也只会丢失一秒的数据

##### 真的只会丢失一秒数据？

准确来说，“丢失一秒数据” 是不准确的。为了解释清楚这件事，我们来介绍一个Redis的内部函数 `flushAppendOnlyFile` 

这个函数执行两个工作：

1. 把 AOF 缓冲区的内容写入到AOF文件中 —— write
2. 把 AOF 文件写入到磁盘里 —— save

这两个工作的具体执行情况，则根据上述三种保存配置来决定：

- always 

在 always 情况下，每次执行完一个命令，wirte 和 save 都会被执行，尤其 save 是 Redis 主进程来完成，所以在 save 期间，**会造成阻塞**

- no

在 no 情况下，save 操作会被略过，write 则会执行
那么 AOF 的同步只会在如下几种情况下完成：
1. Redis 被关闭
2. AOF 被关闭
3. Redis 需要刷新缓存（缓存写满或定期保存操作执行）

- everysec

在 everysec 情况下，理论上，应该会每秒保存一次数据，但是在实际运行中，程序对 `fsync` 或 `fdatasync` 的调用并不是每秒一次，这和调用 `flushAppendOnlyFile` 函数时 Redis 所处的环境相关。我们例举出这几种状态：

1. 当前子进程正在执行 save 操作：
    - 若 save 操作执行时间未超过 2 秒，则直接返回，write 和 save 操作都不会执行
    - 若 save 操作执行时间超过 2 秒，则执行 write ，但不执行 **新的** save 操作
        - 在这里，新的 write 操作必须要等待原先的 save 操作执行完才能执行，因此这里可能会发生更长时间的阻塞
2. 当前子进程未在执行 save 操作：
    - 若距离上次执行 save 操作时间不足 1 秒，执行 write ，不执行 save
    - 若距离上次执行 save 操作时间超过 1 秒，那么 write 和 save 都会执行

由上描述，我们可以看到，

若当前子进程正在执行 save 操作，但 save 操作执行时间 **未超过 2 秒** 时，突然发生宕机故障，那么我们在此时会丢失 **不超过 2 秒** 的数据

若当前子进程正在执行 save 操作，且 save 操作执行时间 **超过 2 秒** 时，突然发生宕机故障，那么我们在此时会丢失 **超过 2 秒** 的数据

#### 文件重写

在上述内容中我们说，AOF 文件会随着运行时写命令的增加而膨胀，当它膨胀到一个极限时，会触发 AOF 文件重写。

AOF 文件重写实际上是把 Redis 进程内的数据转化为写命令同步到新 AOF 文件的过程。

重写后的 AOF 文件在理论上讲，时小于或等于原 AOF 文件的：

1. AOF 重写会去除无效命令。
    - 旧的 AOF 文件内包含同步来的写命令，而这些写命令可能是针对某几个数据的大量修改操作
    - 新的 AOF 文件时直接一句内存中数据生成的，没有这些冗余无用的命令语句
2. 多条写命令可以合并成一个，且针对 `list` / `set` / `zset` 等类型的操作，以 64 个元素为界拆分多条

AOF 文件的重写，也可以手动触发或自动触发，手动触发需要执行 `bgrewriteaof` 命令

自动触发则需要如下两个配置行：

```bash
auto-aof-rewrite-percentage 100
auto-aof-rewrite-min-size 64mb
```
`auto-aof-rewrite-percentage` 当前 AOF 文件空间 (`aof_current_size`) 与上次重写后 AOF 文件空间 (`aof_base_size`) 的比值
`auto-aof-rewrite-min-size` 运行 AOF 重写时文件最小空间

自动触发需要满足如下两个条件

-  `aof_current_size` > `auto-aof-rewrite-min-size` 

- ( `aof_current_size`-`aof_base_size` ) / `aof_base_size` >= `auto-aof-rewrite-percentage`

##### AOF 重写内部机制

AOF 的主要过程，是由主进程 fork 出一个子进程，该子进程共享父进程的内存空间，由此子进程读取当前内存数据，生成新的 AOF 文件，开展 AOF 重写操作。

当重写完成后，将用新的 AOF 文件替换旧的 AOF 文件

简单的思考这个过程，我们发现：

**在重写过程中，主进程并非是阻塞的，那么这个时候新进入的写命令也应该写进 AOF 文件里，该如何处理？**


主进程 fork 出一个子进程开始 AOF 重写时，使用 `copy-on-write` ( 写时复制 ) 技术，主进程与子进程共享同一个物理存储，此时主进程不会被阻塞，新进入的写命令会被丢进一个叫做 **AOF 重写缓冲区** 的地方

当新的 AOF 文件写入完成后，子进程会通知主进程，由主进程更新统计信息，然后将 AOF 重写缓冲区 里，新进入的命令写入重写后的 AOF 文件，再将新的 AOF 文件刷进硬盘

这样就完成了重写

在这里要说明的是，当重写开启，新进入的命令不止会进入 AOF 重写缓冲区，同样也会进入 AOF 缓冲区，待 AOF 缓冲区达到配置后刷新旧的 AOF 文件

—— 我只是想通过重写缩小 AOF 文件，旧的 AOF 文件只有在重写完成被替换的时刻才宣告无用。所以同样的命令一式两份，保证原有 AOF 机制正确，仍然是有意义的。

另外

子进程按照合并规则把命令写入新的 AOF 文件。

每次批量写入硬盘数据量由配置行 `aof-rewrite-incremental-fsync` 控制.防止单次刷盘数据过多造成硬盘阻塞。


### 持久化运维

在这里我想跟大家价绍 Redis 在持久化的时候可能会碰到的几个运维问题

1. 持久化阻塞主线程
我们在介绍 RDB 和 AOF 的时候，曾有几次提到了阻塞，现在来对在持久化过程中，可能会引起主线程阻塞的情况做一个汇总：

    1. RDB 的 save 命令
    2. fork 过程 —— fork 需要 `copy page entry table` 到子进程中去，由于内存量与系统，可能会造成主线程阻塞
    3. AOF 追加阻塞

AOF 追加阻塞实际上是一个 IO 问题，在《Redis开发与运维》中，作者团队这样描述：

>
> 当开启AOF持久化时，常用的同步硬盘的策略是everysec，用于平衡性能和数据安全性。
>
> 对于这种方式，Redis使用另一条线程每秒执行fsync同步硬盘。
>
> 当系统硬盘资源繁忙时，会造成Redis主线程阻塞
>

2. 多实例环境下的 AOF 重写优化

在生产环境中使用 Redis 的时候，为了更大效率地利用系统资源，我们会在同一台物理机上配置多个 Redis 实例，当多个实例开启 AOF ，尤其是开启 AOF 重写之后，彼此之间会产生对 CPU 和 IO 的疯狂抢夺

我们为了避免这样的情况出现，更多的是采用 **人为控制** 的方法，使得实例与实例之间的 AOF 重写操作按照串行化调度。

这里需要介绍的，是几个可以帮助我们完成外部监控重写操作的指标：

```bash
# Persistence
loading:0
rdb_changes_since_last_save:0
rdb_bgsave_in_progress:0                # bgsave子进程是否在进行
rdb_last_save_time:1556018465
rdb_last_bgsave_status:ok
rdb_last_bgsave_time_sec:-1
rdb_current_bgsave_time_sec:-1          # 当前运行 bgsave 的时间 -1 表示未运行
rdb_last_cow_size:0
aof_enabled:0                           # 是否开启 AOF 功能
aof_rewrite_in_progress:0               # AOF 重写子进程是否在运行
aof_rewrite_scheduled:0                 # 在 bgsave 结束后是否运行 AOF 重写
aof_last_rewrite_time_sec:-1
aof_current_rewrite_time_sec:-1         # 当前 AOF 重写运行的时间 -1 表示未运行
aof_last_bgrewrite_status:ok
aof_last_write_status:ok
aof_last_cow_size:0
```

基于以上指标，我们可以使用外部程序轮询控制 AOF 重写操作的执行，完成人为的串行化调度